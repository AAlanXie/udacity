{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be4294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0de6779c0fc44f696d66b90962d21d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    }
   ],
   "source": [
    "%%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4444e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6e575a0a064a9785de20c08d9229a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_data = \"s3a://udacity-dend/\"\n",
    "output_data = \"s3://udacity-spark-project/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec845554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917f85518372477b86d0e70fb7fed17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get filepath to song data file\n",
    "song_data = input_data + 'song_data/*/*/*/*.json'\n",
    "\n",
    "# read song data file\n",
    "df = spark.read.json(song_data)\n",
    "\n",
    "# extract columns to create songs table\n",
    "df.createOrReplaceTempView(\"songs_table\")\n",
    "songs_table = spark.sql(\"\"\"\n",
    "select \n",
    "    song_id, \n",
    "    title, \n",
    "    artist_id, \n",
    "    year, \n",
    "    duration\n",
    "from songs_table\n",
    "where song_id is not null\n",
    "\"\"\")\n",
    "\n",
    "# write songs table to parquet files partitioned by year and artist\n",
    "#     songs_table.write.mode('overwrite').partitionBy('year', 'artist_id').parquet(output_data+'songs_table/')\n",
    "\n",
    "# extract columns to create artists table\n",
    "artists_table = spark.sql(\"\"\"\n",
    "select \n",
    "    artist_id,\n",
    "    artist_name as name,\n",
    "    artist_location as location,\n",
    "    artist_latitude as latitude,\n",
    "    artist_longitude as longitude\n",
    "from songs_table\n",
    "where artist_id is not null\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44571830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742242429edb417bb1b686b5a722f93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get filepath to log data file\n",
    "log_data = input_data + 'log_data/*/*/*.json'\n",
    "\n",
    "# read log data file\n",
    "df1 = spark.read.json(log_data)\n",
    "\n",
    "# filter by actions for song plays\n",
    "df1.filter(df1.page == 'NextSong')\n",
    "df1.createOrReplaceTempView('log_table')\n",
    "\n",
    "# extract columns for users table    \n",
    "users_table = spark.sql(\"\"\"\n",
    "select\n",
    "    userId as user_id, \n",
    "    firstName as first_name, \n",
    "    lastName as last_name, \n",
    "    gender, \n",
    "    level\n",
    "from log_table\n",
    "where userId is not null\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# extract columns to create time table\n",
    "time_table = spark.sql(\"\"\"\n",
    "select \n",
    "    start_time, \n",
    "    hour(start_time) as hour, \n",
    "    dayofmonth(start_time) as day, \n",
    "    weekofyear(start_time) as week, \n",
    "    month(start_time) as month, \n",
    "    year(start_time) as year, \n",
    "    dayofweek(start_time) as weekday\n",
    "from\n",
    "(\n",
    "    select \n",
    "        to_timestamp(ts/1000) as start_time\n",
    "    from log_table\n",
    "    where ts is not null\n",
    ") as a\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# extract columns from joined song and log datasets to create songplays table \n",
    "songplays_table = spark.sql(\"\"\"\n",
    "select \n",
    "    monotonically_increasing_id() as songplay_id, \n",
    "    a.start_time, \n",
    "    month(a.start_time) as month,\n",
    "    year(a.start_time) as year,\n",
    "    a.user_id, \n",
    "    a.level, \n",
    "    b.song_id, \n",
    "    b.artist_id, \n",
    "    a.session_id, \n",
    "    a.location, \n",
    "    a.user_agent\n",
    "from \n",
    "(\n",
    "    select \n",
    "        to_timestamp(ts/1000) as start_time,\n",
    "        userId as user_id,\n",
    "        level,\n",
    "        sessionId as session_id,\n",
    "        location,\n",
    "        userAgent as user_agent,\n",
    "        song\n",
    "    from log_table\n",
    ") as a\n",
    "inner join\n",
    "(\n",
    "    select\n",
    "        song_id,\n",
    "        artist_id,\n",
    "        title\n",
    "    from \n",
    "        songs_table\n",
    ") as b\n",
    "on a.song = b.title\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c24e680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efdf7e2e4b04ce4b2d0d4ecea3d735d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|gender|count(userId)|\n",
      "+------+-------------+\n",
      "|  null|          286|\n",
      "|     M|         2288|\n",
      "|     F|         5482|\n",
      "+------+-------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select\n",
    "    gender,\n",
    "    count(userId)\n",
    "from log_table\n",
    "where userId is not null\n",
    "group by gender\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table.createOrReplaceTempView('songsplay')\n",
    "spark.sql(\"\"\"\n",
    "select year, month, count(songplay_id) from songsplay group by year, month\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321cbce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
